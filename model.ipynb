{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to include other two camera images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24108\n",
      "24108\n"
     ]
    }
   ],
   "source": [
    "# List for each line of the csv file\n",
    "lines = []\n",
    "\n",
    "# Open *.csv file using csv module\n",
    "with open('C:\\\\Users\\\\vDrone\\\\Desktop\\\\Project 3. Behaviour Cloning\\\\data\\\\driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)   \n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "        \n",
    "# Lists for images and steering value\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "# Load images and steering values and append them to the lists\n",
    "for line in lines:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('/')[-1]\n",
    "\n",
    "        current_path = 'C:\\\\Users\\\\vDrone\\\\Desktop\\\\Project 3. Behaviour Cloning\\\\data\\\\IMG\\\\' + filename\n",
    "        current_path = str(current_path)\n",
    "\n",
    "        image = cv2.imread(current_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # For drive.py and OpenCV conflict\n",
    "        images.append(image)\n",
    "    #     print(images)\n",
    "        \n",
    "        correction = 0.1\n",
    "        measurement = float(line[3])\n",
    "        \n",
    "        if i == 0:\n",
    "            measurements.append(measurement)        \n",
    "        elif i == 1:\n",
    "            measurements.append(measurement + correction)\n",
    "        elif i == 2:\n",
    "            measurements.append(measurement - correction)\n",
    "     \n",
    "# print the length of lists to verify whether data is loaded properly or not.    \n",
    "print(len(images))\n",
    "print(len(measurements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.1, -0.1, 0.0, 0.1, -0.1]\n"
     ]
    }
   ],
   "source": [
    "print(measurements[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augumention :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augmented_images, augmented_measurements = [], []\n",
    "\n",
    "for image,measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement*-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data to Numpy Array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48216 48216\n"
     ]
    }
   ],
   "source": [
    "# Convert Images and Steering values to numpy arrays since keras requires them in that form\n",
    "X_train = np.array(augmented_images)\n",
    "Y_train = np.array(augmented_measurements)\n",
    "\n",
    "print(len(X_train), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest Model for checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.....\n",
      "Train on 38572 samples, validate on 9644 samples\n",
      "Epoch 1/5\n",
      "38572/38572 [==============================] - 478s - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 2/5\n",
      "38572/38572 [==============================] - 482s - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 3/5\n",
      "38572/38572 [==============================] - 480s - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 4/5\n",
      "38572/38572 [==============================] - 1458s - loss: 0.0089 - val_loss: 0.0111\n",
      "Epoch 5/5\n",
      "38572/38572 [==============================] - 482s - loss: 0.0085 - val_loss: 0.0116\n",
      "Time required to train the model:  3384.6756026744843\n",
      "Model saved to the directory.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First Layer: Normalizing, Mean Centering the image and cropping the image\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3))) \n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "\n",
    "# Second Layer: Convolutional Layer\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "\n",
    "# Third Layer: Convolutional Layer\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "\n",
    "# Fourth Layer: Convolutional Layer\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "\n",
    "# Fifth Layer: Convolutional Layer\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "\n",
    "# Sixth Layer: Convolutional Layer\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Seventh Layer: Fully connected Layer\n",
    "model.add(Dense(100))\n",
    "\n",
    "# Eightth Layer: Fully connected Layer\n",
    "model.add(Dense(50))\n",
    "\n",
    "# Nineth Layer: Fully connected Layer\n",
    "model.add(Dense(10))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "t1 = time.time()\n",
    "print('Training.....')\n",
    "\n",
    "# Compile and train\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, Y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "\n",
    "t2 = time.time()\n",
    "print('Time required to train the model: ', t2-t1)\n",
    "\n",
    "# save trained model\n",
    "model.save('model.h5')\n",
    "print('Model saved to the directory.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
